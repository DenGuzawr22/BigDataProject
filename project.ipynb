{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:04:17.852633Z",
     "iopub.status.busy": "2023-01-20T11:04:17.852384Z",
     "iopub.status.idle": "2023-01-20T11:04:17.869294Z",
     "shell.execute_reply": "2023-01-20T11:04:17.868662Z",
     "shell.execute_reply.started": "2023-01-20T11:04:17.852607Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'executorMemory': '8G', 'numExecutors': 2, 'executorCores': 3, 'conf': {'spark.dynamicAllocation.enabled': 'false'}, 'proxyUser': 'assumed-role_voclabs_user2193318_Denys_Grushchak', 'kind': 'spark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\"executorMemory\":\"8G\", \"numExecutors\":2, \"executorCores\":3, \"conf\": {\"spark.dynamicAllocation.enabled\": \"false\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:04:20.334399Z",
     "iopub.status.busy": "2023-01-20T11:04:20.334163Z",
     "iopub.status.idle": "2023-01-20T11:04:53.685421Z",
     "shell.execute_reply": "2023-01-20T11:04:53.684639Z",
     "shell.execute_reply.started": "2023-01-20T11:04:20.334375Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c028f572f4c04ff19c23395dd3eed7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>6</td><td>application_1674204611665_0007</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-4-86.ec2.internal:20888/proxy/application_1674204611665_0007/\" class=\"emr-proxy-link\" emr-resource=\"j-1HFX3HU8GAC6H\n",
       "\" application-id=\"application_1674204611665_0007\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-6-137.ec2.internal:8042/node/containerlogs/container_1674204611665_0007_01_000001/livy\" >Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketname: String = unibo-bd2122-dgrushchak\n",
      "path: String = s3a://unibo-bd2122-dgrushchak/project/small_file_10000000.txt\n",
      "res3: String = application_1674204611665_0007\n",
      "res5: String = SPARK UI: Enable forwarding of port 20888 and connect to http://localhost:20888/proxy/application_1674204611665_0007/\n"
     ]
    }
   ],
   "source": [
    "val bucketname = \"unibo-bd2122-dgrushchak\"\n",
    "\n",
    "val path = \"s3a://\"+bucketname+\"/project/small_file_10000000.txt\" \n",
    "\n",
    "sc.applicationId\n",
    "\n",
    "\"SPARK UI: Enable forwarding of port 20888 and connect to http://localhost:20888/proxy/\" + sc.applicationId + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:06:40.714321Z",
     "iopub.status.busy": "2023-01-20T11:06:40.714093Z",
     "iopub.status.idle": "2023-01-20T11:06:41.485550Z",
     "shell.execute_reply": "2023-01-20T11:06:41.484855Z",
     "shell.execute_reply.started": "2023-01-20T11:06:40.714287Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65767ca781724db08ff150dd92e56a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commaRegex: String = ,(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)\n",
      "defined class FlightData\n",
      "defined object FlightData\n",
      "warning: previously defined class FlightData is not a companion to object FlightData.\n",
      "Companions must be defined together; you may wish to use :paste mode for this.\n"
     ]
    }
   ],
   "source": [
    "// import java.util.Calendar\n",
    "// import org.apache.spark.sql.SaveMode\n",
    "// import org.apache.spark.HashPartitioner\n",
    "val commaRegex = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "// object Parser {\n",
    "\n",
    "//       val noGenresListed = \"(no genres listed)\"\n",
    "      \n",
    "//       val pipeRegex = \"\\\\|(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "//       val quotes = \"\\\"\"\n",
    "\n",
    "//       //TODO check\n",
    "//       /** Convert from timestamp (String) to year (Int) */\n",
    "//       def yearFromTimestamp(timestamp: String): Int = {\n",
    "//         val cal = Calendar.getInstance()\n",
    "//         cal.setTimeInMillis(timestamp.trim.toLong * 1000L)\n",
    "//         cal.get(Calendar.YEAR)\n",
    "//       }\n",
    "\n",
    "\n",
    "//         // TODO redo\n",
    "//       /** Function to parse rating records\n",
    "//        *\n",
    "//        *  @param line line that has to be parsed\n",
    "//        *  @return tuple containing userId, movieId, rating, and year none in case of input errors\n",
    "//        */\n",
    "//       def parseRatingLine(line: String): Option[(Long, Long, Double, Int)] = {\n",
    "//         try {\n",
    "//           val input = line.split(commaRegex)\n",
    "//           Some(input(0).trim.toLong, input(1).trim.toLong, input(2).trim.toDouble, yearFromTimestamp(input(3)))\n",
    "//         } catch {\n",
    "//           case _: Exception => None\n",
    "//         }\n",
    "//       }\n",
    "    \n",
    "\n",
    "//     /**\n",
    "//     2 - flightdate\n",
    "//     3 - starting airport\n",
    "//     4 - destination airport\n",
    "//     6 - travel duration (PT2H35M)\n",
    "//     8 - isBasicEconomy (boolean)\n",
    "//     9 - isrefundable (boolean)\n",
    "//     10 - isNonStop (boolean)\n",
    "//     11 - basefare (prezzo base del ticket in $ Double)\n",
    "//     12 - seats remaining (Int)\n",
    "//     20 - airline name (company name)\n",
    "//     22 - airplane type (Vector of [String||String]\n",
    "//     24 - segment distancd (distance in milles: Vector of [Int||Int]  can be [None||None])\n",
    "//     **/\n",
    "   \n",
    "// }\n",
    "\n",
    "case class FlightData(\n",
    "    startAirport:String,\n",
    "    destinationAirport:String\n",
    ")\n",
    "\n",
    "object FlightData {\n",
    "     def extract(line: String) = {\n",
    "//         val input = line.split(commaRegex)\n",
    "        new FlightData(\"one\", \"two\")\n",
    "    }\n",
    "}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:17:19.432334Z",
     "iopub.status.busy": "2023-01-20T11:17:19.432102Z",
     "iopub.status.idle": "2023-01-20T11:17:20.705266Z",
     "shell.execute_reply": "2023-01-20T11:17:20.704522Z",
     "shell.execute_reply.started": "2023-01-20T11:17:19.432310Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5314aac1e244a6ab7bbec43ba7fe11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: ClassNotFound with classloader: org.apache.livy.rsc.driver.MutableClassLoader@408a0c6d\n",
      "  at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2863)\n",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2799)\n",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2798)\n",
      "  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2798)\n",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1239)\n",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1239)\n",
      "  at scala.Option.foreach(Option.scala:407)\n",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1239)\n",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3051)\n",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2993)\n",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2229)\n",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2250)\n",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2269)\n",
      "  at org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1470)\n",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n",
      "  at org.apache.spark.rdd.RDD.take(RDD.scala:1443)\n",
      "  ... 51 elided\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val rdd = sc.textFile(path).map(FlightData.extract)\n",
    "rdd.take(10)\n",
    "println(\"cio\")\n",
    "// rdd.limit(10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative queries\n",
    "\n",
    "1. How many distinct airports and aircraft models\n",
    "2. Average travel duration for airline\n",
    "3. Percentage of basic economy tickets, based on all tickets\n",
    "4. Percentage of non-stop flights (flights with one leg)\n",
    "5. Average and price range of tickets\n",
    "6. Average ticket price for each airline\n",
    "7. Average and range of travel distance\n",
    "8. Top 10 airports with more arriving flights flights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T10:28:35.481942Z",
     "iopub.status.busy": "2023-01-20T10:28:35.481721Z",
     "iopub.status.idle": "2023-01-20T10:28:36.243325Z",
     "shell.execute_reply": "2023-01-20T10:28:36.242604Z",
     "shell.execute_reply.started": "2023-01-20T10:28:35.481919Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb4d7e50269462ca9bf09f38b415fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res20: Option[org.apache.spark.Partitioner] = None\n",
      "rddCache: rdd.type = MapPartitionsRDD[20] at flatMap at <console>:40\n"
     ]
    }
   ],
   "source": [
    "rdd.coalesce(12).partitioner\n",
    "val rddCache = rdd.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T10:32:58.437780Z",
     "iopub.status.busy": "2023-01-20T10:32:58.437566Z",
     "iopub.status.idle": "2023-01-20T10:32:58.703284Z",
     "shell.execute_reply": "2023-01-20T10:32:58.702537Z",
     "shell.execute_reply.started": "2023-01-20T10:32:58.437757Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f50d03e17f9428a9cbb6af13e6b4f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "<console>:39: error: value concat is not a member of org.apache.spark.rdd.RDD[String]\n",
      "       val ris = rddCache.map(x => x._1).concat(rdd.cache.map(x => x._2)).distinct.count\n",
      "                                         ^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val ris = rddCache.map(x => x._1).concat(rdd.cache.map(x => x._2)).distinct.count\n",
    "ris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal works\n",
    "\n",
    "> Basta una query compicata a testa\n",
    "\n",
    "Query approfondite:\n",
    "\n",
    "- Denys:\n",
    "    - Aggrego “airline” e “aircraft model” per determinare il prezzo medio di un miglio nautico, e dopo aggrego (MIN) su “aircraft model” per trovare l'airline che vende i biglietti più economici per quel modello.\n",
    "    - Aggrego su “aircraft model” per calcolare la “travel distance” totale percorsa da ogni modello, poi faccio self-join e aggregazione per determinare il “travel duration” per ogni “aircraft model”. Alla fine determino la velocità di ogni modello partendo dai dati aggregati.\n",
    "- Riccardo:\n",
    "    - Aggrego su “aircraft models” per calcolare la classifica discreta dei modelli più usati rispetto a ciascuna “airline”. Eseguo il join col dataset originale, infine riaggrego su “travel duration” e sulla classificazione di prima. Ottengo la durata di media di ogni volo per ogni compagnia (oltre a numero di voli e totale di ore) sul modello di aereo più utilizzato\n",
    "    - Aggrego su giorno ed airline per calcolare la distanza totale, poi aggrego su airline per calcolare la media dei totali giornalieri (di distanza) per ciascuna compagnia aerea\n",
    "    - Aggrego su aeroporto di arrivo e di partenza, calcolando per ogni copia un AVG dei prezzi dei biglietti. Join con dataset originale. Aggrego nuovamente sulla classificazione di prima e sulla distanza totale percorsa. Ottengo così per ogni tratta il prezzo medio e la distanza media percorsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "val path_output = \"s3a://\"+bucketname+\"/spark/avgRatPerMovie\" //todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
