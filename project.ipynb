{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\"executorMemory\":\"8G\", \"numExecutors\":2, \"executorCores\":3, \"conf\": {\"spark.dynamicAllocation.enabled\": \"false\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//Denys: val bucketname = \"unibo-bd2122-dgrushchak\"\n",
    "//Riccardo: val bucketname = \"unibo-bd2223-rbacca\"\n",
    "\n",
    "val bucketname =\"unibo-bd2122-dgrushchak\"\n",
    "\n",
    "//Denys: val path_flights_db = \"s3a://\"+bucketname+\"/projectTest/xaa.txt\"\n",
    "//Denys: val path_flights_db =  \"s3a://\"+bucketname+\"/project/small_file_10000000.txt\"\n",
    "//Riccardo:val path_flights_db = \"s3a://\"+bucketname+\"/bigdata-project/part_1.txt\"\n",
    "\n",
    "val path_flights_db =  \"s3a://\"+bucketname+\"/project/\"\n",
    "\n",
    "sc.applicationId\n",
    "\n",
    "\"SPARK UI: Enable forwarding of port 20888 and connect to http://localhost:20888/proxy/\" + sc.applicationId + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parsing\n",
    "This parser make flights flat on base of number of the leg.\n",
    "\n",
    "If a flight has two legs it will be splitted into 2 rows that:\n",
    "* duplicate for each row the fields as: `id`, `flightDate`, `startingAirport`, `destinationAirport`, `isNonStop`, `isBasicEconomy`.\n",
    "* has one value of the two that was saved together in fields as: `airplaneType`, `airlineName`, `segmentDistance`, `segmentDuration`.\n",
    "* recalculate a `totalFare` for each row on base of `segmentDistance`. Sum of two rows must return the original value of `totalFare`\n",
    "\n",
    "id is a new field that replace the orinal identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type MyTuple = (String, String, String, String, String, Boolean, Boolean, Double, Int, Int)\n",
    "\n",
    "case class FlatFlightData(\n",
    "    id: Long,                   //1\n",
    "    flightDate: String,         //2      \n",
    "    startingAirport: String,    //3 \n",
    "    destinationAirport: String, //4\n",
    "    airplaneType: String,       //5\n",
    "    airlineName: String,        //6\n",
    "    isNonStop: Boolean,         //7 \n",
    "    isBasicEconomy: Boolean,    //8 \n",
    "    totalFare: Double,          //9\n",
    "    segmentDuration: Int,     //10\n",
    "    segmentDistance: Int      //11\n",
    ") extends Serializable{\n",
    "    // return a tuple of the object\n",
    "    def un() = FlatFlightData.unapply(this).get \n",
    "}\n",
    "\n",
    "\n",
    "object FlatParser{\n",
    "    import scala.collection.mutable.ArrayBuffer\n",
    "    import scala.collection.mutable.ListBuffer\n",
    "    val commaRegex = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "    val doubleVerticalLine = \"\\\\|\\\\|\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def convertAirplaneType(value: String): Array[String] = {\n",
    "        //Ex. input Airbus A320||Boeing 737-800\n",
    "        val result = value.split(doubleVerticalLine)\n",
    "        if (result.contains(\"\")) Array.empty\n",
    "        else result\n",
    "    }\n",
    "    \n",
    "    def convertAirlineName(value: String): Array[String] = {\n",
    "        val result = value.split(doubleVerticalLine)\n",
    "        if (result.contains(\"\")) Array.empty\n",
    "        else result\n",
    "    }\n",
    "    \n",
    "    //return array of duration of each leg in minutes\n",
    "    def convertSegmentsDuration(value: String): Array[Int] = {\n",
    "        val result = value.split(doubleVerticalLine)\n",
    "        if (result.contains(\"\")) Array.empty\n",
    "        else result.map(_.toInt/60)\n",
    "    }\n",
    "    \n",
    "    def convertSegmentsDistance(value: String): Array[Int] = {\n",
    "        val result = value.split(doubleVerticalLine)\n",
    "        if(result.contains(\"\") || result.head == \"None\") Array.empty\n",
    "        else result.map(_.toInt)\n",
    "    }\n",
    "   \n",
    "    def parseFlightInformationLine(line: String): Option[ListBuffer[MyTuple]] = {\n",
    "        try {\n",
    "            val input = line.split(commaRegex)\n",
    "            \n",
    "            val airplanes = convertAirplaneType(input(23)) //airplane type [String||String] \n",
    "            val airline = convertAirlineName(input(21)) // airliine name  [String||String]\n",
    "            val segmentsDuration = convertSegmentsDuration(input(24)) // segments duration in seconds (but the function return duration in minutes)\n",
    "            val segmentsDistance = convertSegmentsDistance(input(25))// segment distance in milles: Vector of [Int||Int]  can be [None||None]\n",
    "            if (airplanes.isEmpty || \n",
    "                airline.isEmpty || \n",
    "                segmentsDuration.isEmpty || \n",
    "                segmentsDistance.isEmpty|| \n",
    "                airplanes.length != airline.length ||\n",
    "                airplanes.length != segmentsDuration.length ||\n",
    "                airplanes.length != segmentsDistance.length ) None\n",
    "            else {\n",
    "                val arr: ListBuffer[MyTuple] = ListBuffer()\n",
    "                val distanceSum = segmentsDistance.reduce(_+_).toDouble\n",
    "                for (i <- 0 until airplanes.length){\n",
    "                    val legPriceBasedOnDistance: Double = (segmentsDistance(i).toDouble/distanceSum) * input(12).toDouble //12 baseFare in $\n",
    "                    arr += ((input(2), //flightdate\n",
    "                             input(3), //starting airport\n",
    "                             input(4), //destination airport\n",
    "                             airplanes(i),\n",
    "                             airline(i),\n",
    "                             input(10).toBoolean,  //isNonStop\n",
    "                             input(8).toBoolean,  //isBasicEconomy\n",
    "                             legPriceBasedOnDistance,\n",
    "                             segmentsDuration(i),\n",
    "                             segmentsDistance(i))\n",
    "                    )\n",
    "                }\n",
    "                Some(arr)\n",
    "            }\n",
    "        } catch {\n",
    "            case _: Exception => None\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tolerance for duplicated data\n",
    "The original dataset has many duplicated record. \n",
    "We decide to create a new dataset that has original format but have not duplicated records, then we could to use this new dataset as new main source of data for elaboration.\n",
    "\n",
    "After elaboration of 10 GB of data we find out that only 1.2 GB of data are unique and this is less than is requested by project requirement, at this point we decided to continue using the original duplicated dataset even if it is practically not correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "This code:\n",
    "1. Read and parse the original data\n",
    "2. Create a new numeric identifier\n",
    "3. Replace original textual identifier and insert the data in FlatFlighData class\n",
    "4. Create a cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.getPersistentRDDs.foreach(_._2.unpersist()) \n",
    "import org.apache.spark.storage.StorageLevel._\n",
    "//zipWithIndex trigger a spark job, for not parse twice all the data we save parsed data on the disk\n",
    "val parsedData = sc.textFile(path_flights_db).flatMap(FlatParser.parseFlightInformationLine).persist(DISK_ONLY)\n",
    "\n",
    "val rddFlightsCached = parsedData.\n",
    "    zipWithIndex(). // Introduce numeric id for each flight row\n",
    "    map({case (v, i) => (i, v)}).\n",
    "    flatMapValues(m => m).\n",
    "    map({case (k, v) => FlatFlightData.apply(k, v._1, v._2, v._3, v._4, v._5, v._6, v._7, v._8, v._9, v._10)}).persist(MEMORY_AND_DISK)\n",
    "//     map({case (k, v) => FlatFlightData.apply(k, v._2, v._3, v._4, v._5, v._6, v._7, v._8, v._9, v._10, v._11)}).cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddFlightsCached.map(_.un).take(10).foreach(println)\n",
    "\n",
    "val numberOfRecords = rddFlightsCached.map(_.id).distinct.count\n",
    "val totalNumberOfTuples = rddFlightsCached.count\n",
    "\n",
    "\n",
    "def round(v: Double): Double = {\n",
    "    (v*100).toInt/100.toDouble\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative queries\n",
    "\n",
    "1. How many distinct airports and aircraft models\n",
    "2. Average travel duration for airline, only in non-stop flights\n",
    "3. Percentage of basic economy tickets, based on all tickets\n",
    "4. Percentage of non-stop flights (flights with one leg)\n",
    "5. Average and price range of tickets\n",
    "6. Average ticket price for each airline\n",
    "7. Average and range of travel distance\n",
    "8. Top 10 airports with more arriving flights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//1.How many distinct airports and aircraft models\n",
    "val distinctAirports = rddFlightsCached.\n",
    "    map(x => x.startingAirport).\n",
    "    distinct.\n",
    "    union(rddFlightsCached.map(x => x.destinationAirport).distinct).\n",
    "    distinct.count\n",
    "val distinctAircraftModels = rddFlightsCached.flatMap(x => x.airplaneType).distinct.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//2. Average travel duration for each airline, in non stop flights\n",
    "val distinctAirlines = rddFlightsCached.\n",
    "    map(x => (x.airlineName, x.segmentDuration)).\n",
    "    aggregateByKey((0.0, 0.0))((a,v)=>(a._1+v, a._2+1), (a1,a2)=>(a1._1+a2._1, a1._2+a2._2)).\n",
    "    map({case(k,v)=>(k,v._1/v._2)}).\n",
    "    collect().\n",
    "    foreach({case (airline, value) => println(airline + \" => \" + round(value) + \" avg minutes\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//3. Percentage of basic economy tickets, based on all tickets\n",
    "round((rddFlightsCached.filter(_.isBasicEconomy).map(_.id).distinct.count.toDouble/numberOfRecords).toDouble*100) + \" %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//4. Percentage of non-stop flights (flights with one leg)\n",
    "round((rddFlightsCached.filter(_.isNonStop).map(_.id).distinct.count.toDouble/numberOfRecords).toDouble*100) + \" %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//5. Average and price range of tickets\n",
    "val ticketPrices = rddFlightsCached.map(x => (x.id,x.totalFare)).reduceByKey(_+_).map(_._2)\n",
    "\"Range of prices: \"  + ticketPrices.min + \" to \" + ticketPrices.max\n",
    "\"Avg price: \" + round((ticketPrices.sum/numberOfRecords).toDouble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//6. Average ticket price for each airline\n",
    "val avgTicketPricePerAirline = rddFlightsCached.\n",
    "    map(x => (x.airlineName,(x.totalFare, 1))).\n",
    "    reduceByKey((a,b) => (a._1+b._1, a._2+b._2)).\n",
    "    map(m => (m._1,m._2._1/m._2._2)).\n",
    "    collect.foreach({case (name, value) => println(name + \" => \" + round(value))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//7. Average and range of travel distance\n",
    "val travelDistances = rddFlightsCached.map(x => (x.id, x.segmentDistance)).reduceByKey(_+_).map(_._2)\n",
    "\"Range of distances: \"  + travelDistances.min + \" to \" + travelDistances.max\n",
    "\"Avg travel distance: \" + round((travelDistances.sum/numberOfRecords).toDouble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//8. Top 10 airports with more arriving flights\n",
    "val topAirports = rddFlightsCached.\n",
    "    map(x => (x.id, x.destinationAirport)).\n",
    "    distinct().\n",
    "    map(m => (m._2, 1)).\n",
    "    reduceByKey(_+_).    \n",
    "    sortBy(_._2, false).\n",
    "    take(10).\n",
    "    foreach({case (name, value) => println(name + \" => \" + value)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val path_output = \"s3a://\"+bucketname+\"/spark/avgRatPerMovie\" //todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riccardo\n",
    "\n",
    "> Riccardo: Aggrego su aeroporto di arrivo e di partenza, calcolando per ogni coppia un AVG dei prezzi dei biglietti. Join con dataset originale. Aggrego nuovamente sulla classificazione di prima e sulla distanza totale percorsa. Ottengo così per ogni tratta il prezzo medio e la distanza media percorsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "// Query approfondita --> Riccardo\n",
    "\n",
    "// Prima aggregate poi Join\n",
    "val result = rddFlightsCached.\n",
    "    map(x => ((x.startingAirport, x.destinationAirport), (x.totalFare, 1))).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v._1, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    map({case (k,(sum,cnt)) => (k, (sum/cnt))}).\n",
    "    join(rddFlightsCached.map(x => ((x.startingAirport, x.destinationAirport), x.segmentDistance)).\n",
    "        aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "        map({case (k,(sum,cnt)) => (k, (sum/cnt))})).\n",
    "    sortByKey().\n",
    "    take(10).foreach(println)\n",
    "\n",
    "\n",
    "// Prima Join poi aggregate\n",
    "/*val result = rddFlightsCached.\n",
    "    map(x => ((x.startingAirport, x.destinationAirport), (x.totalFare, 1))).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v._1, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    map({case (k,(sum,cnt)) => (k, (sum/cnt))}).\n",
    "    join(rddFlightsCached.map(x => ((x.startingAirport, x.destinationAirport), x.segmentDistance))). //([startingAirport, arrivingAirport], [prezzo medio, distanza percorsa])\n",
    "    aggregateByKey((0.0,0.0,0.0))((a,v)=>(a._1+v._2, a._2+1, v._1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2,a1._2)).\n",
    "    map({case (k,(sum,cnt,avg)) => (k, (sum/cnt,avg))}).\n",
    "    map({case (k,(v1,v2)) => (k, (v2,v1))}).\n",
    "    sortByKey().\n",
    "    take(10).foreach(println)*/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-26T17:47:01.300868Z",
     "iopub.status.busy": "2023-01-26T17:47:01.300635Z",
     "iopub.status.idle": "2023-01-26T17:47:01.561303Z",
     "shell.execute_reply": "2023-01-26T17:47:01.560507Z",
     "shell.execute_reply.started": "2023-01-26T17:47:01.300844Z"
    },
    "tags": []
   },
   "source": [
    "### Denys\n",
    "I will calculate the velocity of each airplane type\n",
    "> Denys: aggrego su “airplane model” per calcolare la “segment distance” totale percorsa da ogni modello, poi faccio self-join e aggregazione per determinare il “travel duration” per ogni “airplane model”. Alla fine determino la velocità media di ogni modello partendo dai dati aggregati. Visualizzo 10 aerei con la velocità media più alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//return velocity in miles per hour\n",
    "def getVelocity(distance: Int, durationInMinutes: Int): Double = {\n",
    "    round(distance.toDouble/(durationInMinutes.toDouble/60))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T18:28:01.319109Z",
     "iopub.status.busy": "2023-01-30T18:28:01.318837Z",
     "iopub.status.idle": "2023-01-30T18:28:01.587699Z",
     "shell.execute_reply": "2023-01-30T18:28:01.586817Z",
     "shell.execute_reply.started": "2023-01-30T18:28:01.319080Z"
    },
    "tags": []
   },
   "source": [
    "First solution is exactly as in the problem description: agregation two values separately and then join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val totalAirplanesDistance = rddFlightsCached.map(m => (m.airplaneType, m.segmentDistance)).reduceByKey(_+_)\n",
    "val totalAirplanesDuration = rddFlightsCached.map(m => (m.airplaneType, m.segmentDuration)).reduceByKey(_+_)\n",
    "\n",
    "totalAirplanesDistance.join(totalAirplanesDuration).\n",
    "    map({case (name, (dis, dur)) =>  (name, getVelocity(dis, dur))}).\n",
    "    sortBy(_._2,false).\n",
    "    take(10).\n",
    "    foreach({case (a, v) => println(a + \" ----> \" + v + \" mph\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next implementation I tried to make a repartitioning of the data on base of common key but it gives a worst result because repartioning overhead is much bigger than suffle in the first query.\n",
    "\n",
    "For example: for 7 GB dataset the first query have only ~1Mb of suffle reads and writes while this solution have ~460MB of shuffle writes and ~920MB of shuffle reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val repartitionedValues = rddFlightsCached.map(m => (m.airplaneType, (m.segmentDistance, m.segmentDuration))).repartition(12)\n",
    "\n",
    "val totalAirplanesDistance = repartitionedValues.map(m => (m._1, m._2._1)).reduceByKey(_+_)\n",
    "val totalAirplanesDuration = repartitionedValues.map(m => (m._1, m._2._2)).reduceByKey(_+_)\n",
    "\n",
    "totalAirplanesDistance.join(totalAirplanesDuration).\n",
    "    map({case (name, (dis, dur)) =>  (name, getVelocity(dis, dur))}).\n",
    "    sortBy(_._2,false).\n",
    "    take(10).\n",
    "    foreach({case (a, v) => println(a + \" ----> \" + v + \" mph\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastes way for the velocity calculation is aggregation of two field together. This approach allows not join the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddFlightsCached.\n",
    "    map(m => (m.airplaneType, (m.segmentDistance, m.segmentDuration))).\n",
    "    reduceByKey({case ((dis1, dur1), (dis2, dur2)) => (dis1+dis2, dur1+dur2)}).\n",
    "    map({case (name, (dis, dur)) =>  (name, getVelocity(dis, dur))}).\n",
    "    sortBy(_._2, false).\n",
    "    take(10).\n",
    "    foreach({case (a, v) => println(a + \" ----> \" + v + \" mph\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative velocity valutation: first we calculate medium velocity of each flight and then we calculate the madium velocity for each airplane type. Obviously the result is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddFlightsCached.\n",
    "    map(m => (m.airplaneType, (m.segmentDistance.toDouble, m.segmentDuration.toDouble/60))).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+(v._1/v._2), a._2+1),(a1,a2)=>(a1._1+a2._1, a1._2+a2._2)).\n",
    "    map({case (name, (velocitySum, count)) =>  (name, round(velocitySum/count))}).\n",
    "    sortBy(_._2, false).\n",
    "    take(10).\n",
    "    foreach({case (a, v) => println(a + \" ----> \" + v + \" mph\")})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
